{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb60fb26-63a9-4435-a234-dad9779eb9ae",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7812c20d-8a96-4adf-b2ef-78c54db03901",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from src.models import training, linear_vanilla_vae, denoising_vanilla_vae, skip_vae\n",
    "\n",
    "from src.features import utils\n",
    "from src.features import dataLoader as MyDataLoader\n",
    "import pathlib\n",
    "import PIL\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "from imageaugment import augment\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be133113-e74f-4ffc-aa7a-070b90f81391",
   "metadata": {},
   "source": [
    "# Load Full Samples of Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83490053-d8ce-49c1-8c7e-a5a7a04cb64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor, x_val_tensor, mean, std = utils.load_full_image_tensors(pathlib.Path(\"/home/fahad/master_thesis/data/simulated_noisy_templates_with_gaussian_noise/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a18911-98ba-460a-9acc-c5bdbb34df9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 1, 1536, 1024])\n",
      "torch.Size([800, 1, 1536, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tensor.shape)\n",
    "print(x_val_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd9c2b-c4ce-4ee9-943e-ca53db09011a",
   "metadata": {},
   "source": [
    "# Construct Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5fd7e16-2f7d-45c6-a331-801640d894c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent space dim 8388608\n"
     ]
    }
   ],
   "source": [
    "z_dim=256\n",
    "in_channels = 1\n",
    "init_filters = 32\n",
    "n_filters_per_depth=2\n",
    "n_depth=2\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e8b9b1-985e-4623-9433-16035c539cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = denoising_vanilla_vae.VAE(z_dim=z_dim, in_channels=in_channels,init_filters = init_filters, n_filters_per_depth=n_filters_per_depth,n_depth=n_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d9f13c-fa0f-48ac-a356-6c4d23d2bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=5\n",
    "\n",
    "train_dataset = MyDataLoader.MyDataset(x_train_tensor,x_train_tensor)\n",
    "val_dataset = MyDataLoader.MyDataset(x_val_tensor,x_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "directory_path = \"/home/fahad/master_thesis/vanilla_vae/models/linear_vae/\"\n",
    "n_epochs = 300\n",
    "net = vae\n",
    "device = device\n",
    "\n",
    "lr=0.001\n",
    "val_loss_patience = 100\n",
    "data_mean = mean.item()\n",
    "data_std = std.item()\n",
    "gaussian_noise_std = 1.0\n",
    "\n",
    "model_name = \"template-\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd48e0-82a7-4e4b-bec6-a2d53418a143",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda941b6-2f76-4480-a8d4-486a144e782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainHist, reconHistory, klHist, valHist = training.trainNetwork(net=net, train_loader=train_loader, \n",
    "                                                                 val_loader=val_loader,\n",
    "                                                                 device=device,directory_path=directory_path,\n",
    "                                                                 model_name=model_name,\n",
    "                                                                 n_epochs=n_epochs, batch_size=batch_size,lr=lr,\n",
    "                                                                 val_loss_patience = val_loss_patience,\n",
    "                                                                 kl_annealing = True,\n",
    "                                                                 kl_start = 0, \n",
    "                                                                 kl_annealtime = 3,\n",
    "                                                                 data_mean =data_mean,data_std=data_std, \n",
    "                                                                 gaussian_noise_std = gaussian_noise_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f1273-09d9-4582-930e-7e18779446fb",
   "metadata": {},
   "source": [
    "# Skip VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aeb8e5b-402a-4af7-960c-975d89025129",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "net = skip_vae.VAE(\n",
    "    conv_layers=32,\n",
    "    z_dimension=64,\n",
    "    pool_kernel_size=2,\n",
    "    conv_kernel_size=4,\n",
    "    input_channels=1,\n",
    "    height=1536,\n",
    "    width=1024,\n",
    "    hidden_dim=128,\n",
    "    use_cuda=USE_CUDA,\n",
    "    use_skip_connections=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ac4688-62f8-41cc-8155-365bb7a5e4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
